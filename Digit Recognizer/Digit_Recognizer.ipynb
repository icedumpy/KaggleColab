{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit Recognizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNT2lm/fO1sdECWHmhr9R2U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/icedumpy/KaggleColab/blob/main/Digit%20Recognizer/Digit_Recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omIoiMSFc5uZ"
      },
      "source": [
        "#Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFyfDbHfDuEV",
        "outputId": "c9d9a9d8-0068-4fdc-a154-8138730578b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/MyDrive/Kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/MyDrive/Kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy35ZbFzc4Q_"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWP5Sb0WG6LB"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m93bLUQmddmx"
      },
      "source": [
        "# Execute"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoPDSfZ98aDp"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fSaiNcScsVi"
      },
      "source": [
        "df_train = pd.read_csv(\"Digit Recognizer/train.csv\")\n",
        "df_test  = pd.read_csv(\"Digit Recognizer/test.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMe7cNfc8cTC"
      },
      "source": [
        "## Get data  (image, label)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaNHDxCHdaQp"
      },
      "source": [
        "x = df_train.iloc[:, 1:].values.astype(\"uint8\")\n",
        "y = df_train[\"label\"].values.astype(\"uint8\")\n",
        "\n",
        "x_test = df_test.values.astype(\"uint8\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e6PcHU88jqI"
      },
      "source": [
        "## Reshape image (1D -> 2D) and Normalize (scale [0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VEseSxt8pQR"
      },
      "source": [
        "x = x.reshape(-1, 28, 28, 1)\n",
        "x_test  = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# x = x/255.0\n",
        "# x_test  = x_test/255.0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svFS2d3UD45e"
      },
      "source": [
        "## Split data into train, validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vu4VgKwEFWO"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=112)\n",
        "\n",
        "mean = x_train.mean()\n",
        "std = x_train.std()\n",
        "\n",
        "x_train = (x_train-mean)/std\n",
        "x_val = (x_val-mean)/std\n",
        "x_test = (x_test-mean)/std"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNX9R3CQ9UoG"
      },
      "source": [
        "## Visualize "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "qU8-B8hSex3P",
        "outputId": "c3569771-0dd3-4b34-b05c-07b7e140a4d2"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    index = np.random.randint(0, len(x_train)+1)\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.imshow(x_train[index, :, :, 0], cmap='gray')\n",
        "    plt.xlabel(y_train[index])\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TfGi6kI9wYW"
      },
      "source": [
        "## Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUiNVokn1q4S",
        "outputId": "3f4a9487-32ce-401f-c1fe-54459d8d17e9"
      },
      "source": [
        "input = keras.layers.Input((28, 28, 1))\n",
        "x = keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_uniform')(input)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.LeakyReLU()(x)\n",
        "x = keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_uniform')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.LeakyReLU()(x)\n",
        "x = keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_uniform')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.LeakyReLU()(x)\n",
        "x = keras.layers.Dropout(0.4)(x)\n",
        "\n",
        "x = keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(2, 2), padding=\"valid\", kernel_initializer='he_uniform')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.LeakyReLU()(x)\n",
        "\n",
        "x = keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_uniform')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.LeakyReLU()(x)\n",
        "x = keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_uniform')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.LeakyReLU()(x)\n",
        "x = keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_uniform')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.LeakyReLU()(x)\n",
        "x = keras.layers.Dropout(0.4)(x)\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = keras.layers.Dense(128)(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.LeakyReLU()(x)\n",
        "\n",
        "x = keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=input, outputs=x)\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 26, 26, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 26, 26, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 22, 22, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 22, 22, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 10, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 10, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 6, 6, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 612,234\n",
            "Trainable params: 610,570\n",
            "Non-trainable params: 1,664\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE5X2nqpDGW6"
      },
      "source": [
        "## Complie model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yy--iuK29kj"
      },
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI9WYPGCDINf"
      },
      "source": [
        "## Define callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWRmxrkvDKTd"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\"Digit Recognizer/model.hdf5\", monitor='val_accuracy', verbose= 2, save_best_only=True, mode='max')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20, min_lr=1e-8, verbose=2)\n",
        "earlystop = EarlyStopping(monitor='val_loss', mode='min', patience=50, verbose=2)\n",
        "callbacks_list = [checkpoint, reduce_lr, earlystop]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNJ1ndmBF6cF"
      },
      "source": [
        "## Calculate class weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MZRvzdjF8NT",
        "outputId": "a0391f0f-e3a5-4a0a-936c-00a070f3d0de"
      },
      "source": [
        "class_weight = y_train.shape[0]/(10*np.bincount(y_train))\n",
        "class_weight_dict = dict(enumerate(class_weight))\n",
        "class_weight_dict"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.018799272286234,\n",
              " 1: 0.9063933099541408,\n",
              " 2: 1.0029850746268656,\n",
              " 3: 0.9821689564454837,\n",
              " 4: 1.018181818181818,\n",
              " 5: 1.0926829268292684,\n",
              " 6: 1.0203461888855148,\n",
              " 7: 0.9502262443438914,\n",
              " 8: 1.0316241940435984,\n",
              " 9: 0.9991079393398751}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx5jlqCAKpY0"
      },
      "source": [
        "## Define datagenerator (for Augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9-WcBoiKo8N"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqw4Gc2D3Cca",
        "outputId": "f7d5a3e4-15ff-47a9-ccbb-0d1d99d6a420"
      },
      "source": [
        "model.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=128), \n",
        "    steps_per_epoch=len(x_train)//128,\n",
        "    validation_data = (x_val, y_val),\n",
        "    epochs=150,\n",
        "    callbacks = callbacks_list,\n",
        "    class_weight = class_weight_dict\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.5820 - accuracy: 0.9056\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.92619, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 11s 40ms/step - loss: 1.5817 - accuracy: 0.9058 - val_loss: 1.5401 - val_accuracy: 0.9262\n",
            "Epoch 2/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.5048 - accuracy: 0.9635\n",
            "Epoch 00002: val_accuracy improved from 0.92619 to 0.97690, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.5048 - accuracy: 0.9636 - val_loss: 1.4866 - val_accuracy: 0.9769\n",
            "Epoch 3/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4950 - accuracy: 0.9716\n",
            "Epoch 00003: val_accuracy improved from 0.97690 to 0.97917, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4950 - accuracy: 0.9716 - val_loss: 1.4830 - val_accuracy: 0.9792\n",
            "Epoch 4/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4888 - accuracy: 0.9762\n",
            "Epoch 00004: val_accuracy did not improve from 0.97917\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4887 - accuracy: 0.9762 - val_loss: 1.4922 - val_accuracy: 0.9700\n",
            "Epoch 5/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4883 - accuracy: 0.9762\n",
            "Epoch 00005: val_accuracy improved from 0.97917 to 0.98167, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 40ms/step - loss: 1.4882 - accuracy: 0.9763 - val_loss: 1.4805 - val_accuracy: 0.9817\n",
            "Epoch 6/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4856 - accuracy: 0.9779\n",
            "Epoch 00006: val_accuracy did not improve from 0.98167\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4855 - accuracy: 0.9780 - val_loss: 1.4807 - val_accuracy: 0.9806\n",
            "Epoch 7/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4834 - accuracy: 0.9797\n",
            "Epoch 00007: val_accuracy improved from 0.98167 to 0.98786, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4834 - accuracy: 0.9797 - val_loss: 1.4745 - val_accuracy: 0.9879\n",
            "Epoch 8/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4834 - accuracy: 0.9801\n",
            "Epoch 00008: val_accuracy did not improve from 0.98786\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4834 - accuracy: 0.9801 - val_loss: 1.4777 - val_accuracy: 0.9842\n",
            "Epoch 9/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4809 - accuracy: 0.9824\n",
            "Epoch 00009: val_accuracy did not improve from 0.98786\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4810 - accuracy: 0.9823 - val_loss: 1.4771 - val_accuracy: 0.9844\n",
            "Epoch 10/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4810 - accuracy: 0.9817\n",
            "Epoch 00010: val_accuracy did not improve from 0.98786\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4810 - accuracy: 0.9817 - val_loss: 1.4785 - val_accuracy: 0.9833\n",
            "Epoch 11/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4796 - accuracy: 0.9827\n",
            "Epoch 00011: val_accuracy improved from 0.98786 to 0.98833, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4796 - accuracy: 0.9827 - val_loss: 1.4740 - val_accuracy: 0.9883\n",
            "Epoch 12/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4789 - accuracy: 0.9833\n",
            "Epoch 00012: val_accuracy did not improve from 0.98833\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4789 - accuracy: 0.9833 - val_loss: 1.4740 - val_accuracy: 0.9879\n",
            "Epoch 13/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4790 - accuracy: 0.9836\n",
            "Epoch 00013: val_accuracy did not improve from 0.98833\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4791 - accuracy: 0.9836 - val_loss: 1.4746 - val_accuracy: 0.9869\n",
            "Epoch 14/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4777 - accuracy: 0.9847\n",
            "Epoch 00014: val_accuracy improved from 0.98833 to 0.98964, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4777 - accuracy: 0.9847 - val_loss: 1.4721 - val_accuracy: 0.9896\n",
            "Epoch 15/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4785 - accuracy: 0.9840\n",
            "Epoch 00015: val_accuracy did not improve from 0.98964\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4785 - accuracy: 0.9840 - val_loss: 1.4768 - val_accuracy: 0.9856\n",
            "Epoch 16/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4764 - accuracy: 0.9861\n",
            "Epoch 00016: val_accuracy did not improve from 0.98964\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4764 - accuracy: 0.9861 - val_loss: 1.4762 - val_accuracy: 0.9845\n",
            "Epoch 17/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4780 - accuracy: 0.9842\n",
            "Epoch 00017: val_accuracy did not improve from 0.98964\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4779 - accuracy: 0.9842 - val_loss: 1.4744 - val_accuracy: 0.9877\n",
            "Epoch 18/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4769 - accuracy: 0.9850\n",
            "Epoch 00018: val_accuracy improved from 0.98964 to 0.98976, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4769 - accuracy: 0.9850 - val_loss: 1.4718 - val_accuracy: 0.9898\n",
            "Epoch 19/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4759 - accuracy: 0.9860\n",
            "Epoch 00019: val_accuracy improved from 0.98976 to 0.99155, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4759 - accuracy: 0.9860 - val_loss: 1.4702 - val_accuracy: 0.9915\n",
            "Epoch 20/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4764 - accuracy: 0.9855\n",
            "Epoch 00020: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4765 - accuracy: 0.9854 - val_loss: 1.4736 - val_accuracy: 0.9879\n",
            "Epoch 21/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4750 - accuracy: 0.9867\n",
            "Epoch 00021: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4750 - accuracy: 0.9867 - val_loss: 1.4723 - val_accuracy: 0.9886\n",
            "Epoch 22/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4752 - accuracy: 0.9866\n",
            "Epoch 00022: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4753 - accuracy: 0.9865 - val_loss: 1.4727 - val_accuracy: 0.9886\n",
            "Epoch 23/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4742 - accuracy: 0.9876\n",
            "Epoch 00023: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4742 - accuracy: 0.9876 - val_loss: 1.4726 - val_accuracy: 0.9886\n",
            "Epoch 24/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4756 - accuracy: 0.9858\n",
            "Epoch 00024: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4756 - accuracy: 0.9858 - val_loss: 1.4738 - val_accuracy: 0.9875\n",
            "Epoch 25/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4753 - accuracy: 0.9866\n",
            "Epoch 00025: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4753 - accuracy: 0.9866 - val_loss: 1.4700 - val_accuracy: 0.9914\n",
            "Epoch 26/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4749 - accuracy: 0.9868\n",
            "Epoch 00026: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4750 - accuracy: 0.9868 - val_loss: 1.4709 - val_accuracy: 0.9904\n",
            "Epoch 27/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4750 - accuracy: 0.9869\n",
            "Epoch 00027: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4751 - accuracy: 0.9869 - val_loss: 1.4746 - val_accuracy: 0.9862\n",
            "Epoch 28/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4737 - accuracy: 0.9880\n",
            "Epoch 00028: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4737 - accuracy: 0.9880 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
            "Epoch 29/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4724 - accuracy: 0.9891\n",
            "Epoch 00029: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4724 - accuracy: 0.9891 - val_loss: 1.4716 - val_accuracy: 0.9899\n",
            "Epoch 30/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4743 - accuracy: 0.9873\n",
            "Epoch 00030: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4742 - accuracy: 0.9874 - val_loss: 1.4715 - val_accuracy: 0.9899\n",
            "Epoch 31/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4738 - accuracy: 0.9879\n",
            "Epoch 00031: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4737 - accuracy: 0.9880 - val_loss: 1.4717 - val_accuracy: 0.9894\n",
            "Epoch 32/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4733 - accuracy: 0.9881\n",
            "Epoch 00032: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4734 - accuracy: 0.9881 - val_loss: 1.4727 - val_accuracy: 0.9886\n",
            "Epoch 33/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4744 - accuracy: 0.9872\n",
            "Epoch 00033: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4744 - accuracy: 0.9872 - val_loss: 1.4703 - val_accuracy: 0.9906\n",
            "Epoch 34/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4726 - accuracy: 0.9891\n",
            "Epoch 00034: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4726 - accuracy: 0.9892 - val_loss: 1.4705 - val_accuracy: 0.9912\n",
            "Epoch 35/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4724 - accuracy: 0.9890\n",
            "Epoch 00035: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4724 - accuracy: 0.9890 - val_loss: 1.4715 - val_accuracy: 0.9901\n",
            "Epoch 36/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4725 - accuracy: 0.9892\n",
            "Epoch 00036: val_accuracy improved from 0.99155 to 0.99250, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4725 - accuracy: 0.9892 - val_loss: 1.4688 - val_accuracy: 0.9925\n",
            "Epoch 37/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4730 - accuracy: 0.9885\n",
            "Epoch 00037: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4731 - accuracy: 0.9885 - val_loss: 1.4710 - val_accuracy: 0.9908\n",
            "Epoch 38/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4727 - accuracy: 0.9888\n",
            "Epoch 00038: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4727 - accuracy: 0.9888 - val_loss: 1.4700 - val_accuracy: 0.9913\n",
            "Epoch 39/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4723 - accuracy: 0.9891\n",
            "Epoch 00039: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4723 - accuracy: 0.9891 - val_loss: 1.4742 - val_accuracy: 0.9871\n",
            "Epoch 40/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4712 - accuracy: 0.9903\n",
            "Epoch 00040: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4713 - accuracy: 0.9903 - val_loss: 1.4727 - val_accuracy: 0.9885\n",
            "Epoch 41/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4717 - accuracy: 0.9900\n",
            "Epoch 00041: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4716 - accuracy: 0.9901 - val_loss: 1.4697 - val_accuracy: 0.9917\n",
            "Epoch 42/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4728 - accuracy: 0.9887\n",
            "Epoch 00042: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4727 - accuracy: 0.9887 - val_loss: 1.4801 - val_accuracy: 0.9811\n",
            "Epoch 43/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4718 - accuracy: 0.9898\n",
            "Epoch 00043: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4718 - accuracy: 0.9898 - val_loss: 1.4712 - val_accuracy: 0.9900\n",
            "Epoch 44/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4719 - accuracy: 0.9895\n",
            "Epoch 00044: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4718 - accuracy: 0.9895 - val_loss: 1.4733 - val_accuracy: 0.9879\n",
            "Epoch 45/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4723 - accuracy: 0.9892\n",
            "Epoch 00045: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4723 - accuracy: 0.9892 - val_loss: 1.4726 - val_accuracy: 0.9882\n",
            "Epoch 46/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4706 - accuracy: 0.9911\n",
            "Epoch 00046: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4705 - accuracy: 0.9911 - val_loss: 1.4736 - val_accuracy: 0.9876\n",
            "Epoch 47/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4710 - accuracy: 0.9906\n",
            "Epoch 00047: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4709 - accuracy: 0.9906 - val_loss: 1.4690 - val_accuracy: 0.9924\n",
            "Epoch 48/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4705 - accuracy: 0.9910\n",
            "Epoch 00048: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4705 - accuracy: 0.9910 - val_loss: 1.4690 - val_accuracy: 0.9924\n",
            "Epoch 49/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4709 - accuracy: 0.9904\n",
            "Epoch 00049: val_accuracy improved from 0.99250 to 0.99274, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 40ms/step - loss: 1.4709 - accuracy: 0.9904 - val_loss: 1.4686 - val_accuracy: 0.9927\n",
            "Epoch 50/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4719 - accuracy: 0.9895\n",
            "Epoch 00050: val_accuracy did not improve from 0.99274\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4718 - accuracy: 0.9895 - val_loss: 1.4721 - val_accuracy: 0.9892\n",
            "Epoch 51/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4719 - accuracy: 0.9894\n",
            "Epoch 00051: val_accuracy did not improve from 0.99274\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4719 - accuracy: 0.9894 - val_loss: 1.4720 - val_accuracy: 0.9889\n",
            "Epoch 52/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4719 - accuracy: 0.9895\n",
            "Epoch 00052: val_accuracy improved from 0.99274 to 0.99286, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4720 - accuracy: 0.9895 - val_loss: 1.4688 - val_accuracy: 0.9929\n",
            "Epoch 53/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4705 - accuracy: 0.9911\n",
            "Epoch 00053: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4705 - accuracy: 0.9912 - val_loss: 1.4727 - val_accuracy: 0.9886\n",
            "Epoch 54/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4709 - accuracy: 0.9905\n",
            "Epoch 00054: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4709 - accuracy: 0.9905 - val_loss: 1.4686 - val_accuracy: 0.9927\n",
            "Epoch 55/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4698 - accuracy: 0.9916\n",
            "Epoch 00055: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4698 - accuracy: 0.9916 - val_loss: 1.4712 - val_accuracy: 0.9904\n",
            "Epoch 56/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4704 - accuracy: 0.9908\n",
            "Epoch 00056: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4704 - accuracy: 0.9908 - val_loss: 1.4689 - val_accuracy: 0.9925\n",
            "Epoch 57/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4699 - accuracy: 0.9914\n",
            "Epoch 00057: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4699 - accuracy: 0.9914 - val_loss: 1.4699 - val_accuracy: 0.9912\n",
            "Epoch 58/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4699 - accuracy: 0.9915\n",
            "Epoch 00058: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4699 - accuracy: 0.9915 - val_loss: 1.4704 - val_accuracy: 0.9907\n",
            "Epoch 59/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4726 - accuracy: 0.9887\n",
            "Epoch 00059: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4726 - accuracy: 0.9887 - val_loss: 1.4719 - val_accuracy: 0.9893\n",
            "Epoch 60/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4700 - accuracy: 0.9914\n",
            "Epoch 00060: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4700 - accuracy: 0.9915 - val_loss: 1.4697 - val_accuracy: 0.9919\n",
            "Epoch 61/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4689 - accuracy: 0.9926\n",
            "Epoch 00061: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4689 - accuracy: 0.9926 - val_loss: 1.4687 - val_accuracy: 0.9923\n",
            "Epoch 62/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4700 - accuracy: 0.9914\n",
            "Epoch 00062: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4700 - accuracy: 0.9914 - val_loss: 1.4686 - val_accuracy: 0.9929\n",
            "Epoch 63/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4693 - accuracy: 0.9920\n",
            "Epoch 00063: val_accuracy improved from 0.99286 to 0.99345, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4693 - accuracy: 0.9920 - val_loss: 1.4676 - val_accuracy: 0.9935\n",
            "Epoch 64/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4700 - accuracy: 0.9915\n",
            "Epoch 00064: val_accuracy did not improve from 0.99345\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4700 - accuracy: 0.9915 - val_loss: 1.4704 - val_accuracy: 0.9910\n",
            "Epoch 65/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4695 - accuracy: 0.9919\n",
            "Epoch 00065: val_accuracy did not improve from 0.99345\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4695 - accuracy: 0.9920 - val_loss: 1.4707 - val_accuracy: 0.9907\n",
            "Epoch 66/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4706 - accuracy: 0.9912\n",
            "Epoch 00066: val_accuracy improved from 0.99345 to 0.99357, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4706 - accuracy: 0.9912 - val_loss: 1.4682 - val_accuracy: 0.9936\n",
            "Epoch 67/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4705 - accuracy: 0.9911\n",
            "Epoch 00067: val_accuracy did not improve from 0.99357\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4705 - accuracy: 0.9911 - val_loss: 1.4701 - val_accuracy: 0.9911\n",
            "Epoch 68/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4703 - accuracy: 0.9912\n",
            "Epoch 00068: val_accuracy improved from 0.99357 to 0.99417, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 40ms/step - loss: 1.4703 - accuracy: 0.9912 - val_loss: 1.4672 - val_accuracy: 0.9942\n",
            "Epoch 69/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4704 - accuracy: 0.9908\n",
            "Epoch 00069: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4704 - accuracy: 0.9908 - val_loss: 1.4682 - val_accuracy: 0.9931\n",
            "Epoch 70/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4699 - accuracy: 0.9917\n",
            "Epoch 00070: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4699 - accuracy: 0.9916 - val_loss: 1.4674 - val_accuracy: 0.9937\n",
            "Epoch 71/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4701 - accuracy: 0.9911\n",
            "Epoch 00071: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4701 - accuracy: 0.9911 - val_loss: 1.4690 - val_accuracy: 0.9923\n",
            "Epoch 72/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4696 - accuracy: 0.9914\n",
            "Epoch 00072: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4696 - accuracy: 0.9914 - val_loss: 1.4689 - val_accuracy: 0.9925\n",
            "Epoch 73/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4691 - accuracy: 0.9924\n",
            "Epoch 00073: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4691 - accuracy: 0.9924 - val_loss: 1.4700 - val_accuracy: 0.9913\n",
            "Epoch 74/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4691 - accuracy: 0.9923\n",
            "Epoch 00074: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4691 - accuracy: 0.9923 - val_loss: 1.4711 - val_accuracy: 0.9898\n",
            "Epoch 75/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4693 - accuracy: 0.9921\n",
            "Epoch 00075: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4694 - accuracy: 0.9921 - val_loss: 1.4720 - val_accuracy: 0.9896\n",
            "Epoch 76/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4694 - accuracy: 0.9921\n",
            "Epoch 00076: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4694 - accuracy: 0.9920 - val_loss: 1.4705 - val_accuracy: 0.9910\n",
            "Epoch 77/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4684 - accuracy: 0.9930\n",
            "Epoch 00077: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4684 - accuracy: 0.9930 - val_loss: 1.4707 - val_accuracy: 0.9910\n",
            "Epoch 78/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4702 - accuracy: 0.9912\n",
            "Epoch 00078: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4702 - accuracy: 0.9911 - val_loss: 1.4676 - val_accuracy: 0.9936\n",
            "Epoch 79/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4690 - accuracy: 0.9924\n",
            "Epoch 00079: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4690 - accuracy: 0.9924 - val_loss: 1.4684 - val_accuracy: 0.9929\n",
            "Epoch 80/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4692 - accuracy: 0.9921\n",
            "Epoch 00080: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4692 - accuracy: 0.9921 - val_loss: 1.4693 - val_accuracy: 0.9920\n",
            "Epoch 81/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4690 - accuracy: 0.9922\n",
            "Epoch 00081: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4690 - accuracy: 0.9922 - val_loss: 1.4679 - val_accuracy: 0.9933\n",
            "Epoch 82/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4698 - accuracy: 0.9917\n",
            "Epoch 00082: val_accuracy improved from 0.99417 to 0.99429, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4698 - accuracy: 0.9917 - val_loss: 1.4671 - val_accuracy: 0.9943\n",
            "Epoch 83/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4687 - accuracy: 0.9927\n",
            "Epoch 00083: val_accuracy did not improve from 0.99429\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4687 - accuracy: 0.9927 - val_loss: 1.4696 - val_accuracy: 0.9918\n",
            "Epoch 84/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4686 - accuracy: 0.9927\n",
            "Epoch 00084: val_accuracy did not improve from 0.99429\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4686 - accuracy: 0.9927 - val_loss: 1.4684 - val_accuracy: 0.9929\n",
            "Epoch 85/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4688 - accuracy: 0.9925\n",
            "Epoch 00085: val_accuracy did not improve from 0.99429\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4688 - accuracy: 0.9925 - val_loss: 1.4673 - val_accuracy: 0.9940\n",
            "Epoch 86/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4691 - accuracy: 0.9922\n",
            "Epoch 00086: val_accuracy did not improve from 0.99429\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4691 - accuracy: 0.9922 - val_loss: 1.4684 - val_accuracy: 0.9927\n",
            "Epoch 87/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4685 - accuracy: 0.9930\n",
            "Epoch 00087: val_accuracy did not improve from 0.99429\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4685 - accuracy: 0.9930 - val_loss: 1.4689 - val_accuracy: 0.9925\n",
            "Epoch 88/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4690 - accuracy: 0.9924\n",
            "Epoch 00088: val_accuracy did not improve from 0.99429\n",
            "\n",
            "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4690 - accuracy: 0.9924 - val_loss: 1.4694 - val_accuracy: 0.9917\n",
            "Epoch 89/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4677 - accuracy: 0.9935\n",
            "Epoch 00089: val_accuracy improved from 0.99429 to 0.99476, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4678 - accuracy: 0.9935 - val_loss: 1.4666 - val_accuracy: 0.9948\n",
            "Epoch 90/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4666 - accuracy: 0.9947\n",
            "Epoch 00090: val_accuracy did not improve from 0.99476\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4666 - accuracy: 0.9947 - val_loss: 1.4665 - val_accuracy: 0.9946\n",
            "Epoch 91/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4655 - accuracy: 0.9956\n",
            "Epoch 00091: val_accuracy did not improve from 0.99476\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4655 - accuracy: 0.9956 - val_loss: 1.4666 - val_accuracy: 0.9945\n",
            "Epoch 92/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4651 - accuracy: 0.9962\n",
            "Epoch 00092: val_accuracy improved from 0.99476 to 0.99500, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4651 - accuracy: 0.9962 - val_loss: 1.4662 - val_accuracy: 0.9950\n",
            "Epoch 93/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4654 - accuracy: 0.9959\n",
            "Epoch 00093: val_accuracy did not improve from 0.99500\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4654 - accuracy: 0.9959 - val_loss: 1.4662 - val_accuracy: 0.9950\n",
            "Epoch 94/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4656 - accuracy: 0.9957\n",
            "Epoch 00094: val_accuracy improved from 0.99500 to 0.99512, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 40ms/step - loss: 1.4656 - accuracy: 0.9957 - val_loss: 1.4661 - val_accuracy: 0.9951\n",
            "Epoch 95/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4653 - accuracy: 0.9960\n",
            "Epoch 00095: val_accuracy did not improve from 0.99512\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4653 - accuracy: 0.9959 - val_loss: 1.4663 - val_accuracy: 0.9950\n",
            "Epoch 96/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4651 - accuracy: 0.9962\n",
            "Epoch 00096: val_accuracy did not improve from 0.99512\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4651 - accuracy: 0.9962 - val_loss: 1.4662 - val_accuracy: 0.9951\n",
            "Epoch 97/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4653 - accuracy: 0.9960\n",
            "Epoch 00097: val_accuracy did not improve from 0.99512\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4653 - accuracy: 0.9959 - val_loss: 1.4664 - val_accuracy: 0.9945\n",
            "Epoch 98/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4648 - accuracy: 0.9967\n",
            "Epoch 00098: val_accuracy did not improve from 0.99512\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4648 - accuracy: 0.9967 - val_loss: 1.4662 - val_accuracy: 0.9949\n",
            "Epoch 99/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4650 - accuracy: 0.9963\n",
            "Epoch 00099: val_accuracy improved from 0.99512 to 0.99536, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4650 - accuracy: 0.9963 - val_loss: 1.4658 - val_accuracy: 0.9954\n",
            "Epoch 100/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4648 - accuracy: 0.9963\n",
            "Epoch 00100: val_accuracy did not improve from 0.99536\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4649 - accuracy: 0.9963 - val_loss: 1.4664 - val_accuracy: 0.9948\n",
            "Epoch 101/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4646 - accuracy: 0.9966\n",
            "Epoch 00101: val_accuracy did not improve from 0.99536\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4646 - accuracy: 0.9966 - val_loss: 1.4662 - val_accuracy: 0.9952\n",
            "Epoch 102/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4648 - accuracy: 0.9964\n",
            "Epoch 00102: val_accuracy did not improve from 0.99536\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4648 - accuracy: 0.9964 - val_loss: 1.4659 - val_accuracy: 0.9952\n",
            "Epoch 103/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4646 - accuracy: 0.9967\n",
            "Epoch 00103: val_accuracy did not improve from 0.99536\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4646 - accuracy: 0.9967 - val_loss: 1.4660 - val_accuracy: 0.9952\n",
            "Epoch 104/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4647 - accuracy: 0.9965\n",
            "Epoch 00104: val_accuracy improved from 0.99536 to 0.99560, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4647 - accuracy: 0.9965 - val_loss: 1.4658 - val_accuracy: 0.9956\n",
            "Epoch 105/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4644 - accuracy: 0.9970\n",
            "Epoch 00105: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4644 - accuracy: 0.9970 - val_loss: 1.4660 - val_accuracy: 0.9951\n",
            "Epoch 106/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4645 - accuracy: 0.9968\n",
            "Epoch 00106: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4645 - accuracy: 0.9968 - val_loss: 1.4662 - val_accuracy: 0.9950\n",
            "Epoch 107/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4650 - accuracy: 0.9963\n",
            "Epoch 00107: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4650 - accuracy: 0.9962 - val_loss: 1.4661 - val_accuracy: 0.9950\n",
            "Epoch 108/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4645 - accuracy: 0.9967\n",
            "Epoch 00108: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4645 - accuracy: 0.9967 - val_loss: 1.4664 - val_accuracy: 0.9944\n",
            "Epoch 109/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4645 - accuracy: 0.9968\n",
            "Epoch 00109: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4645 - accuracy: 0.9968 - val_loss: 1.4665 - val_accuracy: 0.9943\n",
            "Epoch 110/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4648 - accuracy: 0.9964\n",
            "Epoch 00110: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4648 - accuracy: 0.9964 - val_loss: 1.4661 - val_accuracy: 0.9949\n",
            "Epoch 111/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4646 - accuracy: 0.9966\n",
            "Epoch 00111: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4646 - accuracy: 0.9966 - val_loss: 1.4664 - val_accuracy: 0.9946\n",
            "Epoch 112/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4645 - accuracy: 0.9966\n",
            "Epoch 00112: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4645 - accuracy: 0.9965 - val_loss: 1.4659 - val_accuracy: 0.9955\n",
            "Epoch 113/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4643 - accuracy: 0.9970\n",
            "Epoch 00113: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4643 - accuracy: 0.9970 - val_loss: 1.4663 - val_accuracy: 0.9945\n",
            "Epoch 114/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4645 - accuracy: 0.9970\n",
            "Epoch 00114: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4645 - accuracy: 0.9969 - val_loss: 1.4662 - val_accuracy: 0.9946\n",
            "Epoch 115/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4640 - accuracy: 0.9973\n",
            "Epoch 00115: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4641 - accuracy: 0.9973 - val_loss: 1.4661 - val_accuracy: 0.9952\n",
            "Epoch 116/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4642 - accuracy: 0.9969\n",
            "Epoch 00116: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4642 - accuracy: 0.9969 - val_loss: 1.4660 - val_accuracy: 0.9950\n",
            "Epoch 117/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4639 - accuracy: 0.9976\n",
            "Epoch 00117: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4639 - accuracy: 0.9976 - val_loss: 1.4658 - val_accuracy: 0.9956\n",
            "Epoch 118/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4641 - accuracy: 0.9971\n",
            "Epoch 00118: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4641 - accuracy: 0.9971 - val_loss: 1.4658 - val_accuracy: 0.9951\n",
            "Epoch 119/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4642 - accuracy: 0.9970\n",
            "Epoch 00119: val_accuracy improved from 0.99560 to 0.99571, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 40ms/step - loss: 1.4642 - accuracy: 0.9970 - val_loss: 1.4657 - val_accuracy: 0.9957\n",
            "Epoch 120/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4643 - accuracy: 0.9969\n",
            "Epoch 00120: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4643 - accuracy: 0.9969 - val_loss: 1.4662 - val_accuracy: 0.9948\n",
            "Epoch 121/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4641 - accuracy: 0.9972\n",
            "Epoch 00121: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4640 - accuracy: 0.9973 - val_loss: 1.4656 - val_accuracy: 0.9955\n",
            "Epoch 122/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4642 - accuracy: 0.9971\n",
            "Epoch 00122: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4642 - accuracy: 0.9971 - val_loss: 1.4658 - val_accuracy: 0.9954\n",
            "Epoch 123/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4642 - accuracy: 0.9971\n",
            "Epoch 00123: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4642 - accuracy: 0.9971 - val_loss: 1.4664 - val_accuracy: 0.9945\n",
            "Epoch 124/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4638 - accuracy: 0.9975\n",
            "Epoch 00124: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4638 - accuracy: 0.9975 - val_loss: 1.4658 - val_accuracy: 0.9952\n",
            "Epoch 125/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4641 - accuracy: 0.9973\n",
            "Epoch 00125: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4641 - accuracy: 0.9973 - val_loss: 1.4660 - val_accuracy: 0.9955\n",
            "Epoch 126/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4645 - accuracy: 0.9967\n",
            "Epoch 00126: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4646 - accuracy: 0.9967 - val_loss: 1.4662 - val_accuracy: 0.9948\n",
            "Epoch 127/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4644 - accuracy: 0.9968\n",
            "Epoch 00127: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4644 - accuracy: 0.9968 - val_loss: 1.4661 - val_accuracy: 0.9949\n",
            "Epoch 128/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4638 - accuracy: 0.9975\n",
            "Epoch 00128: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4638 - accuracy: 0.9976 - val_loss: 1.4659 - val_accuracy: 0.9955\n",
            "Epoch 129/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4640 - accuracy: 0.9974\n",
            "Epoch 00129: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4640 - accuracy: 0.9974 - val_loss: 1.4658 - val_accuracy: 0.9955\n",
            "Epoch 130/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4641 - accuracy: 0.9970\n",
            "Epoch 00130: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4641 - accuracy: 0.9970 - val_loss: 1.4659 - val_accuracy: 0.9954\n",
            "Epoch 131/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4643 - accuracy: 0.9969\n",
            "Epoch 00131: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4643 - accuracy: 0.9969 - val_loss: 1.4659 - val_accuracy: 0.9951\n",
            "Epoch 132/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4639 - accuracy: 0.9974\n",
            "Epoch 00132: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4639 - accuracy: 0.9974 - val_loss: 1.4655 - val_accuracy: 0.9956\n",
            "Epoch 133/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4640 - accuracy: 0.9974\n",
            "Epoch 00133: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4639 - accuracy: 0.9974 - val_loss: 1.4656 - val_accuracy: 0.9954\n",
            "Epoch 134/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4641 - accuracy: 0.9971\n",
            "Epoch 00134: val_accuracy improved from 0.99571 to 0.99595, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 11s 40ms/step - loss: 1.4641 - accuracy: 0.9971 - val_loss: 1.4653 - val_accuracy: 0.9960\n",
            "Epoch 135/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4639 - accuracy: 0.9974\n",
            "Epoch 00135: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4639 - accuracy: 0.9974 - val_loss: 1.4658 - val_accuracy: 0.9956\n",
            "Epoch 136/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4639 - accuracy: 0.9973\n",
            "Epoch 00136: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4639 - accuracy: 0.9973 - val_loss: 1.4657 - val_accuracy: 0.9954\n",
            "Epoch 137/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4639 - accuracy: 0.9974\n",
            "Epoch 00137: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4639 - accuracy: 0.9974 - val_loss: 1.4656 - val_accuracy: 0.9955\n",
            "Epoch 138/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4641 - accuracy: 0.9972\n",
            "Epoch 00138: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4641 - accuracy: 0.9972 - val_loss: 1.4656 - val_accuracy: 0.9955\n",
            "Epoch 139/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4638 - accuracy: 0.9976\n",
            "Epoch 00139: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4638 - accuracy: 0.9976 - val_loss: 1.4656 - val_accuracy: 0.9952\n",
            "Epoch 140/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4638 - accuracy: 0.9973\n",
            "Epoch 00140: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4638 - accuracy: 0.9973 - val_loss: 1.4655 - val_accuracy: 0.9957\n",
            "Epoch 141/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4636 - accuracy: 0.9978\n",
            "Epoch 00141: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 11s 40ms/step - loss: 1.4636 - accuracy: 0.9978 - val_loss: 1.4659 - val_accuracy: 0.9952\n",
            "Epoch 142/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4639 - accuracy: 0.9974\n",
            "Epoch 00142: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4639 - accuracy: 0.9974 - val_loss: 1.4657 - val_accuracy: 0.9955\n",
            "Epoch 143/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4639 - accuracy: 0.9974\n",
            "Epoch 00143: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4639 - accuracy: 0.9974 - val_loss: 1.4662 - val_accuracy: 0.9951\n",
            "Epoch 144/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4640 - accuracy: 0.9972\n",
            "Epoch 00144: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4640 - accuracy: 0.9973 - val_loss: 1.4659 - val_accuracy: 0.9952\n",
            "Epoch 145/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4637 - accuracy: 0.9976\n",
            "Epoch 00145: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4637 - accuracy: 0.9976 - val_loss: 1.4657 - val_accuracy: 0.9955\n",
            "Epoch 146/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4641 - accuracy: 0.9974\n",
            "Epoch 00146: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4640 - accuracy: 0.9974 - val_loss: 1.4656 - val_accuracy: 0.9958\n",
            "Epoch 147/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4641 - accuracy: 0.9973\n",
            "Epoch 00147: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4641 - accuracy: 0.9973 - val_loss: 1.4657 - val_accuracy: 0.9955\n",
            "Epoch 148/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4642 - accuracy: 0.9970\n",
            "Epoch 00148: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4642 - accuracy: 0.9970 - val_loss: 1.4654 - val_accuracy: 0.9958\n",
            "Epoch 149/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4641 - accuracy: 0.9972\n",
            "Epoch 00149: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4641 - accuracy: 0.9972 - val_loss: 1.4658 - val_accuracy: 0.9954\n",
            "Epoch 150/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4637 - accuracy: 0.9976\n",
            "Epoch 00150: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4638 - accuracy: 0.9976 - val_loss: 1.4656 - val_accuracy: 0.9955\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efea5876860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0a4aDWD3j8o"
      },
      "source": [
        "model = keras.models.load_model(\"Digit Recognizer/model.hdf5\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3_zKrC6G1U2"
      },
      "source": [
        "pred_test = np.argmax(model.predict(x_test), axis=1)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "dSkzIFhVnMcF",
        "outputId": "dacd3b5b-d681-484e-9016-d9bb4d4a36cb"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    index = np.random.randint(0, len(x_test)+1)\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.imshow(x_test[index, :, :, 0], cmap='gray')\n",
        "    plt.xlabel(pred_test[index])\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "plt.show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUVK-l_1nW7-",
        "outputId": "e32d592f-f74c-4edf-bb09-7a01b7b6d555"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 2, ..., 7, 6, 3], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}