{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit Recognizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNHw4YSxIrwQXkI0cBvPVuX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/icedumpy/KaggleColab/blob/main/Digit%20Recognizer/Digit_Recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omIoiMSFc5uZ"
      },
      "source": [
        "#Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFyfDbHfDuEV",
        "outputId": "c9d9a9d8-0068-4fdc-a154-8138730578b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/MyDrive/Kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/MyDrive/Kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy35ZbFzc4Q_"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWP5Sb0WG6LB"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m93bLUQmddmx"
      },
      "source": [
        "# Execute"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoPDSfZ98aDp"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fSaiNcScsVi"
      },
      "source": [
        "df_train = pd.read_csv(\"Digit Recognizer/train.csv\")\n",
        "df_test  = pd.read_csv(\"Digit Recognizer/test.csv\")\n",
        "\n",
        "df_submission  = pd.read_csv(c)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMe7cNfc8cTC"
      },
      "source": [
        "## Get data  (image, label)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaNHDxCHdaQp"
      },
      "source": [
        "x = df_train.iloc[:, 1:].values.astype(\"uint8\")\n",
        "y = df_train[\"label\"].values.astype(\"uint8\")\n",
        "\n",
        "x_test = df_test.values.astype(\"uint8\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e6PcHU88jqI"
      },
      "source": [
        "## Reshape image (1D -> 2D) and Normalize (scale [0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VEseSxt8pQR"
      },
      "source": [
        "x = x.reshape(-1, 28, 28, 1)\n",
        "x_test  = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# x = x/255.0\n",
        "# x_test  = x_test/255.0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svFS2d3UD45e"
      },
      "source": [
        "## Split data into train, validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vu4VgKwEFWO"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=112)\n",
        "\n",
        "mean = x_train.mean()\n",
        "std = x_train.std()\n",
        "\n",
        "x_train = (x_train-mean)/std\n",
        "x_val = (x_val-mean)/std\n",
        "x_test = (x_test-mean)/std"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNX9R3CQ9UoG"
      },
      "source": [
        "## Visualize "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "qU8-B8hSex3P",
        "outputId": "c3569771-0dd3-4b34-b05c-07b7e140a4d2"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    index = np.random.randint(0, len(x_train)+1)\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.imshow(x_train[index, :, :, 0], cmap='gray')\n",
        "    plt.xlabel(y_train[index])\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TfGi6kI9wYW"
      },
      "source": [
        "## Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUiNVokn1q4S",
        "outputId": "3f4a9487-32ce-401f-c1fe-54459d8d17e9"
      },
      "source": [
        "input = keras.layers.Input((28, 28, 1))\n",
        "x = keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_uniform')(input)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.LeakyReLU()(x)\n",
        "x = keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_uniform')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.LeakyReLU()(x)\n",
        "x = keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_uniform')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.LeakyReLU()(x)\n",
        "x = keras.layers.Dropout(0.4)(x)\n",
        "\n",
        "x = keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(2, 2), padding=\"valid\", kernel_initializer='he_uniform')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.LeakyReLU()(x)\n",
        "\n",
        "x = keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_uniform')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.LeakyReLU()(x)\n",
        "x = keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_uniform')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.LeakyReLU()(x)\n",
        "x = keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_uniform')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.LeakyReLU()(x)\n",
        "x = keras.layers.Dropout(0.4)(x)\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = keras.layers.Dense(128)(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.LeakyReLU()(x)\n",
        "\n",
        "x = keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=input, outputs=x)\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 26, 26, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 26, 26, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 22, 22, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 22, 22, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 10, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 10, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 6, 6, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 612,234\n",
            "Trainable params: 610,570\n",
            "Non-trainable params: 1,664\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE5X2nqpDGW6"
      },
      "source": [
        "## Complie model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yy--iuK29kj"
      },
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI9WYPGCDINf"
      },
      "source": [
        "## Define callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWRmxrkvDKTd"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\"Digit Recognizer/model.hdf5\", monitor='val_accuracy', verbose= 2, save_best_only=True, mode='max')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20, min_lr=1e-8, verbose=2)\n",
        "earlystop = EarlyStopping(monitor='val_loss', mode='min', patience=50, verbose=2)\n",
        "callbacks_list = [checkpoint, reduce_lr, earlystop]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNJ1ndmBF6cF"
      },
      "source": [
        "## Calculate class weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MZRvzdjF8NT",
        "outputId": "a0391f0f-e3a5-4a0a-936c-00a070f3d0de"
      },
      "source": [
        "class_weight = y_train.shape[0]/(10*np.bincount(y_train))\n",
        "class_weight_dict = dict(enumerate(class_weight))\n",
        "class_weight_dict"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.018799272286234,\n",
              " 1: 0.9063933099541408,\n",
              " 2: 1.0029850746268656,\n",
              " 3: 0.9821689564454837,\n",
              " 4: 1.018181818181818,\n",
              " 5: 1.0926829268292684,\n",
              " 6: 1.0203461888855148,\n",
              " 7: 0.9502262443438914,\n",
              " 8: 1.0316241940435984,\n",
              " 9: 0.9991079393398751}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx5jlqCAKpY0"
      },
      "source": [
        "## Define datagenerator (for Augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9-WcBoiKo8N"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqw4Gc2D3Cca",
        "outputId": "f7d5a3e4-15ff-47a9-ccbb-0d1d99d6a420"
      },
      "source": [
        "model.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=128), \n",
        "    steps_per_epoch=len(x_train)//128,\n",
        "    validation_data = (x_val, y_val),\n",
        "    epochs=150,\n",
        "    callbacks = callbacks_list,\n",
        "    class_weight = class_weight_dict\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.5820 - accuracy: 0.9056\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.92619, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 11s 40ms/step - loss: 1.5817 - accuracy: 0.9058 - val_loss: 1.5401 - val_accuracy: 0.9262\n",
            "Epoch 2/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.5048 - accuracy: 0.9635\n",
            "Epoch 00002: val_accuracy improved from 0.92619 to 0.97690, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.5048 - accuracy: 0.9636 - val_loss: 1.4866 - val_accuracy: 0.9769\n",
            "Epoch 3/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4950 - accuracy: 0.9716\n",
            "Epoch 00003: val_accuracy improved from 0.97690 to 0.97917, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4950 - accuracy: 0.9716 - val_loss: 1.4830 - val_accuracy: 0.9792\n",
            "Epoch 4/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4888 - accuracy: 0.9762\n",
            "Epoch 00004: val_accuracy did not improve from 0.97917\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4887 - accuracy: 0.9762 - val_loss: 1.4922 - val_accuracy: 0.9700\n",
            "Epoch 5/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4883 - accuracy: 0.9762\n",
            "Epoch 00005: val_accuracy improved from 0.97917 to 0.98167, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 40ms/step - loss: 1.4882 - accuracy: 0.9763 - val_loss: 1.4805 - val_accuracy: 0.9817\n",
            "Epoch 6/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4856 - accuracy: 0.9779\n",
            "Epoch 00006: val_accuracy did not improve from 0.98167\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4855 - accuracy: 0.9780 - val_loss: 1.4807 - val_accuracy: 0.9806\n",
            "Epoch 7/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4834 - accuracy: 0.9797\n",
            "Epoch 00007: val_accuracy improved from 0.98167 to 0.98786, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4834 - accuracy: 0.9797 - val_loss: 1.4745 - val_accuracy: 0.9879\n",
            "Epoch 8/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4834 - accuracy: 0.9801\n",
            "Epoch 00008: val_accuracy did not improve from 0.98786\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4834 - accuracy: 0.9801 - val_loss: 1.4777 - val_accuracy: 0.9842\n",
            "Epoch 9/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4809 - accuracy: 0.9824\n",
            "Epoch 00009: val_accuracy did not improve from 0.98786\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4810 - accuracy: 0.9823 - val_loss: 1.4771 - val_accuracy: 0.9844\n",
            "Epoch 10/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4810 - accuracy: 0.9817\n",
            "Epoch 00010: val_accuracy did not improve from 0.98786\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4810 - accuracy: 0.9817 - val_loss: 1.4785 - val_accuracy: 0.9833\n",
            "Epoch 11/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4796 - accuracy: 0.9827\n",
            "Epoch 00011: val_accuracy improved from 0.98786 to 0.98833, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4796 - accuracy: 0.9827 - val_loss: 1.4740 - val_accuracy: 0.9883\n",
            "Epoch 12/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4789 - accuracy: 0.9833\n",
            "Epoch 00012: val_accuracy did not improve from 0.98833\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4789 - accuracy: 0.9833 - val_loss: 1.4740 - val_accuracy: 0.9879\n",
            "Epoch 13/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4790 - accuracy: 0.9836\n",
            "Epoch 00013: val_accuracy did not improve from 0.98833\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4791 - accuracy: 0.9836 - val_loss: 1.4746 - val_accuracy: 0.9869\n",
            "Epoch 14/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4777 - accuracy: 0.9847\n",
            "Epoch 00014: val_accuracy improved from 0.98833 to 0.98964, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4777 - accuracy: 0.9847 - val_loss: 1.4721 - val_accuracy: 0.9896\n",
            "Epoch 15/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4785 - accuracy: 0.9840\n",
            "Epoch 00015: val_accuracy did not improve from 0.98964\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4785 - accuracy: 0.9840 - val_loss: 1.4768 - val_accuracy: 0.9856\n",
            "Epoch 16/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4764 - accuracy: 0.9861\n",
            "Epoch 00016: val_accuracy did not improve from 0.98964\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4764 - accuracy: 0.9861 - val_loss: 1.4762 - val_accuracy: 0.9845\n",
            "Epoch 17/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4780 - accuracy: 0.9842\n",
            "Epoch 00017: val_accuracy did not improve from 0.98964\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4779 - accuracy: 0.9842 - val_loss: 1.4744 - val_accuracy: 0.9877\n",
            "Epoch 18/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4769 - accuracy: 0.9850\n",
            "Epoch 00018: val_accuracy improved from 0.98964 to 0.98976, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4769 - accuracy: 0.9850 - val_loss: 1.4718 - val_accuracy: 0.9898\n",
            "Epoch 19/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4759 - accuracy: 0.9860\n",
            "Epoch 00019: val_accuracy improved from 0.98976 to 0.99155, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4759 - accuracy: 0.9860 - val_loss: 1.4702 - val_accuracy: 0.9915\n",
            "Epoch 20/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4764 - accuracy: 0.9855\n",
            "Epoch 00020: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4765 - accuracy: 0.9854 - val_loss: 1.4736 - val_accuracy: 0.9879\n",
            "Epoch 21/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4750 - accuracy: 0.9867\n",
            "Epoch 00021: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4750 - accuracy: 0.9867 - val_loss: 1.4723 - val_accuracy: 0.9886\n",
            "Epoch 22/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4752 - accuracy: 0.9866\n",
            "Epoch 00022: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4753 - accuracy: 0.9865 - val_loss: 1.4727 - val_accuracy: 0.9886\n",
            "Epoch 23/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4742 - accuracy: 0.9876\n",
            "Epoch 00023: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4742 - accuracy: 0.9876 - val_loss: 1.4726 - val_accuracy: 0.9886\n",
            "Epoch 24/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4756 - accuracy: 0.9858\n",
            "Epoch 00024: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4756 - accuracy: 0.9858 - val_loss: 1.4738 - val_accuracy: 0.9875\n",
            "Epoch 25/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4753 - accuracy: 0.9866\n",
            "Epoch 00025: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4753 - accuracy: 0.9866 - val_loss: 1.4700 - val_accuracy: 0.9914\n",
            "Epoch 26/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4749 - accuracy: 0.9868\n",
            "Epoch 00026: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4750 - accuracy: 0.9868 - val_loss: 1.4709 - val_accuracy: 0.9904\n",
            "Epoch 27/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4750 - accuracy: 0.9869\n",
            "Epoch 00027: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4751 - accuracy: 0.9869 - val_loss: 1.4746 - val_accuracy: 0.9862\n",
            "Epoch 28/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4737 - accuracy: 0.9880\n",
            "Epoch 00028: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4737 - accuracy: 0.9880 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
            "Epoch 29/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4724 - accuracy: 0.9891\n",
            "Epoch 00029: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4724 - accuracy: 0.9891 - val_loss: 1.4716 - val_accuracy: 0.9899\n",
            "Epoch 30/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4743 - accuracy: 0.9873\n",
            "Epoch 00030: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4742 - accuracy: 0.9874 - val_loss: 1.4715 - val_accuracy: 0.9899\n",
            "Epoch 31/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4738 - accuracy: 0.9879\n",
            "Epoch 00031: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4737 - accuracy: 0.9880 - val_loss: 1.4717 - val_accuracy: 0.9894\n",
            "Epoch 32/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4733 - accuracy: 0.9881\n",
            "Epoch 00032: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4734 - accuracy: 0.9881 - val_loss: 1.4727 - val_accuracy: 0.9886\n",
            "Epoch 33/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4744 - accuracy: 0.9872\n",
            "Epoch 00033: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4744 - accuracy: 0.9872 - val_loss: 1.4703 - val_accuracy: 0.9906\n",
            "Epoch 34/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4726 - accuracy: 0.9891\n",
            "Epoch 00034: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4726 - accuracy: 0.9892 - val_loss: 1.4705 - val_accuracy: 0.9912\n",
            "Epoch 35/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4724 - accuracy: 0.9890\n",
            "Epoch 00035: val_accuracy did not improve from 0.99155\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4724 - accuracy: 0.9890 - val_loss: 1.4715 - val_accuracy: 0.9901\n",
            "Epoch 36/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4725 - accuracy: 0.9892\n",
            "Epoch 00036: val_accuracy improved from 0.99155 to 0.99250, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4725 - accuracy: 0.9892 - val_loss: 1.4688 - val_accuracy: 0.9925\n",
            "Epoch 37/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4730 - accuracy: 0.9885\n",
            "Epoch 00037: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4731 - accuracy: 0.9885 - val_loss: 1.4710 - val_accuracy: 0.9908\n",
            "Epoch 38/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4727 - accuracy: 0.9888\n",
            "Epoch 00038: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4727 - accuracy: 0.9888 - val_loss: 1.4700 - val_accuracy: 0.9913\n",
            "Epoch 39/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4723 - accuracy: 0.9891\n",
            "Epoch 00039: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4723 - accuracy: 0.9891 - val_loss: 1.4742 - val_accuracy: 0.9871\n",
            "Epoch 40/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4712 - accuracy: 0.9903\n",
            "Epoch 00040: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4713 - accuracy: 0.9903 - val_loss: 1.4727 - val_accuracy: 0.9885\n",
            "Epoch 41/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4717 - accuracy: 0.9900\n",
            "Epoch 00041: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4716 - accuracy: 0.9901 - val_loss: 1.4697 - val_accuracy: 0.9917\n",
            "Epoch 42/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4728 - accuracy: 0.9887\n",
            "Epoch 00042: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4727 - accuracy: 0.9887 - val_loss: 1.4801 - val_accuracy: 0.9811\n",
            "Epoch 43/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4718 - accuracy: 0.9898\n",
            "Epoch 00043: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4718 - accuracy: 0.9898 - val_loss: 1.4712 - val_accuracy: 0.9900\n",
            "Epoch 44/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4719 - accuracy: 0.9895\n",
            "Epoch 00044: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4718 - accuracy: 0.9895 - val_loss: 1.4733 - val_accuracy: 0.9879\n",
            "Epoch 45/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4723 - accuracy: 0.9892\n",
            "Epoch 00045: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4723 - accuracy: 0.9892 - val_loss: 1.4726 - val_accuracy: 0.9882\n",
            "Epoch 46/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4706 - accuracy: 0.9911\n",
            "Epoch 00046: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4705 - accuracy: 0.9911 - val_loss: 1.4736 - val_accuracy: 0.9876\n",
            "Epoch 47/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4710 - accuracy: 0.9906\n",
            "Epoch 00047: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4709 - accuracy: 0.9906 - val_loss: 1.4690 - val_accuracy: 0.9924\n",
            "Epoch 48/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4705 - accuracy: 0.9910\n",
            "Epoch 00048: val_accuracy did not improve from 0.99250\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4705 - accuracy: 0.9910 - val_loss: 1.4690 - val_accuracy: 0.9924\n",
            "Epoch 49/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4709 - accuracy: 0.9904\n",
            "Epoch 00049: val_accuracy improved from 0.99250 to 0.99274, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 40ms/step - loss: 1.4709 - accuracy: 0.9904 - val_loss: 1.4686 - val_accuracy: 0.9927\n",
            "Epoch 50/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4719 - accuracy: 0.9895\n",
            "Epoch 00050: val_accuracy did not improve from 0.99274\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4718 - accuracy: 0.9895 - val_loss: 1.4721 - val_accuracy: 0.9892\n",
            "Epoch 51/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4719 - accuracy: 0.9894\n",
            "Epoch 00051: val_accuracy did not improve from 0.99274\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4719 - accuracy: 0.9894 - val_loss: 1.4720 - val_accuracy: 0.9889\n",
            "Epoch 52/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4719 - accuracy: 0.9895\n",
            "Epoch 00052: val_accuracy improved from 0.99274 to 0.99286, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4720 - accuracy: 0.9895 - val_loss: 1.4688 - val_accuracy: 0.9929\n",
            "Epoch 53/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4705 - accuracy: 0.9911\n",
            "Epoch 00053: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4705 - accuracy: 0.9912 - val_loss: 1.4727 - val_accuracy: 0.9886\n",
            "Epoch 54/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4709 - accuracy: 0.9905\n",
            "Epoch 00054: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4709 - accuracy: 0.9905 - val_loss: 1.4686 - val_accuracy: 0.9927\n",
            "Epoch 55/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4698 - accuracy: 0.9916\n",
            "Epoch 00055: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4698 - accuracy: 0.9916 - val_loss: 1.4712 - val_accuracy: 0.9904\n",
            "Epoch 56/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4704 - accuracy: 0.9908\n",
            "Epoch 00056: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4704 - accuracy: 0.9908 - val_loss: 1.4689 - val_accuracy: 0.9925\n",
            "Epoch 57/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4699 - accuracy: 0.9914\n",
            "Epoch 00057: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4699 - accuracy: 0.9914 - val_loss: 1.4699 - val_accuracy: 0.9912\n",
            "Epoch 58/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4699 - accuracy: 0.9915\n",
            "Epoch 00058: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4699 - accuracy: 0.9915 - val_loss: 1.4704 - val_accuracy: 0.9907\n",
            "Epoch 59/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4726 - accuracy: 0.9887\n",
            "Epoch 00059: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4726 - accuracy: 0.9887 - val_loss: 1.4719 - val_accuracy: 0.9893\n",
            "Epoch 60/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4700 - accuracy: 0.9914\n",
            "Epoch 00060: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4700 - accuracy: 0.9915 - val_loss: 1.4697 - val_accuracy: 0.9919\n",
            "Epoch 61/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4689 - accuracy: 0.9926\n",
            "Epoch 00061: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4689 - accuracy: 0.9926 - val_loss: 1.4687 - val_accuracy: 0.9923\n",
            "Epoch 62/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4700 - accuracy: 0.9914\n",
            "Epoch 00062: val_accuracy did not improve from 0.99286\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4700 - accuracy: 0.9914 - val_loss: 1.4686 - val_accuracy: 0.9929\n",
            "Epoch 63/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4693 - accuracy: 0.9920\n",
            "Epoch 00063: val_accuracy improved from 0.99286 to 0.99345, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4693 - accuracy: 0.9920 - val_loss: 1.4676 - val_accuracy: 0.9935\n",
            "Epoch 64/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4700 - accuracy: 0.9915\n",
            "Epoch 00064: val_accuracy did not improve from 0.99345\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4700 - accuracy: 0.9915 - val_loss: 1.4704 - val_accuracy: 0.9910\n",
            "Epoch 65/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4695 - accuracy: 0.9919\n",
            "Epoch 00065: val_accuracy did not improve from 0.99345\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4695 - accuracy: 0.9920 - val_loss: 1.4707 - val_accuracy: 0.9907\n",
            "Epoch 66/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4706 - accuracy: 0.9912\n",
            "Epoch 00066: val_accuracy improved from 0.99345 to 0.99357, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4706 - accuracy: 0.9912 - val_loss: 1.4682 - val_accuracy: 0.9936\n",
            "Epoch 67/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4705 - accuracy: 0.9911\n",
            "Epoch 00067: val_accuracy did not improve from 0.99357\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4705 - accuracy: 0.9911 - val_loss: 1.4701 - val_accuracy: 0.9911\n",
            "Epoch 68/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4703 - accuracy: 0.9912\n",
            "Epoch 00068: val_accuracy improved from 0.99357 to 0.99417, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 40ms/step - loss: 1.4703 - accuracy: 0.9912 - val_loss: 1.4672 - val_accuracy: 0.9942\n",
            "Epoch 69/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4704 - accuracy: 0.9908\n",
            "Epoch 00069: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4704 - accuracy: 0.9908 - val_loss: 1.4682 - val_accuracy: 0.9931\n",
            "Epoch 70/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4699 - accuracy: 0.9917\n",
            "Epoch 00070: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4699 - accuracy: 0.9916 - val_loss: 1.4674 - val_accuracy: 0.9937\n",
            "Epoch 71/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4701 - accuracy: 0.9911\n",
            "Epoch 00071: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4701 - accuracy: 0.9911 - val_loss: 1.4690 - val_accuracy: 0.9923\n",
            "Epoch 72/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4696 - accuracy: 0.9914\n",
            "Epoch 00072: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4696 - accuracy: 0.9914 - val_loss: 1.4689 - val_accuracy: 0.9925\n",
            "Epoch 73/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4691 - accuracy: 0.9924\n",
            "Epoch 00073: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4691 - accuracy: 0.9924 - val_loss: 1.4700 - val_accuracy: 0.9913\n",
            "Epoch 74/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4691 - accuracy: 0.9923\n",
            "Epoch 00074: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4691 - accuracy: 0.9923 - val_loss: 1.4711 - val_accuracy: 0.9898\n",
            "Epoch 75/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4693 - accuracy: 0.9921\n",
            "Epoch 00075: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4694 - accuracy: 0.9921 - val_loss: 1.4720 - val_accuracy: 0.9896\n",
            "Epoch 76/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4694 - accuracy: 0.9921\n",
            "Epoch 00076: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4694 - accuracy: 0.9920 - val_loss: 1.4705 - val_accuracy: 0.9910\n",
            "Epoch 77/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4684 - accuracy: 0.9930\n",
            "Epoch 00077: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4684 - accuracy: 0.9930 - val_loss: 1.4707 - val_accuracy: 0.9910\n",
            "Epoch 78/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4702 - accuracy: 0.9912\n",
            "Epoch 00078: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4702 - accuracy: 0.9911 - val_loss: 1.4676 - val_accuracy: 0.9936\n",
            "Epoch 79/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4690 - accuracy: 0.9924\n",
            "Epoch 00079: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4690 - accuracy: 0.9924 - val_loss: 1.4684 - val_accuracy: 0.9929\n",
            "Epoch 80/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4692 - accuracy: 0.9921\n",
            "Epoch 00080: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4692 - accuracy: 0.9921 - val_loss: 1.4693 - val_accuracy: 0.9920\n",
            "Epoch 81/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4690 - accuracy: 0.9922\n",
            "Epoch 00081: val_accuracy did not improve from 0.99417\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4690 - accuracy: 0.9922 - val_loss: 1.4679 - val_accuracy: 0.9933\n",
            "Epoch 82/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4698 - accuracy: 0.9917\n",
            "Epoch 00082: val_accuracy improved from 0.99417 to 0.99429, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4698 - accuracy: 0.9917 - val_loss: 1.4671 - val_accuracy: 0.9943\n",
            "Epoch 83/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4687 - accuracy: 0.9927\n",
            "Epoch 00083: val_accuracy did not improve from 0.99429\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4687 - accuracy: 0.9927 - val_loss: 1.4696 - val_accuracy: 0.9918\n",
            "Epoch 84/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4686 - accuracy: 0.9927\n",
            "Epoch 00084: val_accuracy did not improve from 0.99429\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4686 - accuracy: 0.9927 - val_loss: 1.4684 - val_accuracy: 0.9929\n",
            "Epoch 85/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4688 - accuracy: 0.9925\n",
            "Epoch 00085: val_accuracy did not improve from 0.99429\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4688 - accuracy: 0.9925 - val_loss: 1.4673 - val_accuracy: 0.9940\n",
            "Epoch 86/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4691 - accuracy: 0.9922\n",
            "Epoch 00086: val_accuracy did not improve from 0.99429\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4691 - accuracy: 0.9922 - val_loss: 1.4684 - val_accuracy: 0.9927\n",
            "Epoch 87/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4685 - accuracy: 0.9930\n",
            "Epoch 00087: val_accuracy did not improve from 0.99429\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4685 - accuracy: 0.9930 - val_loss: 1.4689 - val_accuracy: 0.9925\n",
            "Epoch 88/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4690 - accuracy: 0.9924\n",
            "Epoch 00088: val_accuracy did not improve from 0.99429\n",
            "\n",
            "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4690 - accuracy: 0.9924 - val_loss: 1.4694 - val_accuracy: 0.9917\n",
            "Epoch 89/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4677 - accuracy: 0.9935\n",
            "Epoch 00089: val_accuracy improved from 0.99429 to 0.99476, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4678 - accuracy: 0.9935 - val_loss: 1.4666 - val_accuracy: 0.9948\n",
            "Epoch 90/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4666 - accuracy: 0.9947\n",
            "Epoch 00090: val_accuracy did not improve from 0.99476\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4666 - accuracy: 0.9947 - val_loss: 1.4665 - val_accuracy: 0.9946\n",
            "Epoch 91/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4655 - accuracy: 0.9956\n",
            "Epoch 00091: val_accuracy did not improve from 0.99476\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4655 - accuracy: 0.9956 - val_loss: 1.4666 - val_accuracy: 0.9945\n",
            "Epoch 92/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4651 - accuracy: 0.9962\n",
            "Epoch 00092: val_accuracy improved from 0.99476 to 0.99500, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4651 - accuracy: 0.9962 - val_loss: 1.4662 - val_accuracy: 0.9950\n",
            "Epoch 93/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4654 - accuracy: 0.9959\n",
            "Epoch 00093: val_accuracy did not improve from 0.99500\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4654 - accuracy: 0.9959 - val_loss: 1.4662 - val_accuracy: 0.9950\n",
            "Epoch 94/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4656 - accuracy: 0.9957\n",
            "Epoch 00094: val_accuracy improved from 0.99500 to 0.99512, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 40ms/step - loss: 1.4656 - accuracy: 0.9957 - val_loss: 1.4661 - val_accuracy: 0.9951\n",
            "Epoch 95/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4653 - accuracy: 0.9960\n",
            "Epoch 00095: val_accuracy did not improve from 0.99512\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4653 - accuracy: 0.9959 - val_loss: 1.4663 - val_accuracy: 0.9950\n",
            "Epoch 96/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4651 - accuracy: 0.9962\n",
            "Epoch 00096: val_accuracy did not improve from 0.99512\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4651 - accuracy: 0.9962 - val_loss: 1.4662 - val_accuracy: 0.9951\n",
            "Epoch 97/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4653 - accuracy: 0.9960\n",
            "Epoch 00097: val_accuracy did not improve from 0.99512\n",
            "262/262 [==============================] - 10s 37ms/step - loss: 1.4653 - accuracy: 0.9959 - val_loss: 1.4664 - val_accuracy: 0.9945\n",
            "Epoch 98/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4648 - accuracy: 0.9967\n",
            "Epoch 00098: val_accuracy did not improve from 0.99512\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4648 - accuracy: 0.9967 - val_loss: 1.4662 - val_accuracy: 0.9949\n",
            "Epoch 99/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4650 - accuracy: 0.9963\n",
            "Epoch 00099: val_accuracy improved from 0.99512 to 0.99536, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4650 - accuracy: 0.9963 - val_loss: 1.4658 - val_accuracy: 0.9954\n",
            "Epoch 100/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4648 - accuracy: 0.9963\n",
            "Epoch 00100: val_accuracy did not improve from 0.99536\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4649 - accuracy: 0.9963 - val_loss: 1.4664 - val_accuracy: 0.9948\n",
            "Epoch 101/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4646 - accuracy: 0.9966\n",
            "Epoch 00101: val_accuracy did not improve from 0.99536\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4646 - accuracy: 0.9966 - val_loss: 1.4662 - val_accuracy: 0.9952\n",
            "Epoch 102/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4648 - accuracy: 0.9964\n",
            "Epoch 00102: val_accuracy did not improve from 0.99536\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4648 - accuracy: 0.9964 - val_loss: 1.4659 - val_accuracy: 0.9952\n",
            "Epoch 103/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4646 - accuracy: 0.9967\n",
            "Epoch 00103: val_accuracy did not improve from 0.99536\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4646 - accuracy: 0.9967 - val_loss: 1.4660 - val_accuracy: 0.9952\n",
            "Epoch 104/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4647 - accuracy: 0.9965\n",
            "Epoch 00104: val_accuracy improved from 0.99536 to 0.99560, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4647 - accuracy: 0.9965 - val_loss: 1.4658 - val_accuracy: 0.9956\n",
            "Epoch 105/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4644 - accuracy: 0.9970\n",
            "Epoch 00105: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4644 - accuracy: 0.9970 - val_loss: 1.4660 - val_accuracy: 0.9951\n",
            "Epoch 106/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4645 - accuracy: 0.9968\n",
            "Epoch 00106: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4645 - accuracy: 0.9968 - val_loss: 1.4662 - val_accuracy: 0.9950\n",
            "Epoch 107/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4650 - accuracy: 0.9963\n",
            "Epoch 00107: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4650 - accuracy: 0.9962 - val_loss: 1.4661 - val_accuracy: 0.9950\n",
            "Epoch 108/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4645 - accuracy: 0.9967\n",
            "Epoch 00108: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4645 - accuracy: 0.9967 - val_loss: 1.4664 - val_accuracy: 0.9944\n",
            "Epoch 109/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4645 - accuracy: 0.9968\n",
            "Epoch 00109: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4645 - accuracy: 0.9968 - val_loss: 1.4665 - val_accuracy: 0.9943\n",
            "Epoch 110/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4648 - accuracy: 0.9964\n",
            "Epoch 00110: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4648 - accuracy: 0.9964 - val_loss: 1.4661 - val_accuracy: 0.9949\n",
            "Epoch 111/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4646 - accuracy: 0.9966\n",
            "Epoch 00111: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4646 - accuracy: 0.9966 - val_loss: 1.4664 - val_accuracy: 0.9946\n",
            "Epoch 112/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4645 - accuracy: 0.9966\n",
            "Epoch 00112: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4645 - accuracy: 0.9965 - val_loss: 1.4659 - val_accuracy: 0.9955\n",
            "Epoch 113/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4643 - accuracy: 0.9970\n",
            "Epoch 00113: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4643 - accuracy: 0.9970 - val_loss: 1.4663 - val_accuracy: 0.9945\n",
            "Epoch 114/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4645 - accuracy: 0.9970\n",
            "Epoch 00114: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4645 - accuracy: 0.9969 - val_loss: 1.4662 - val_accuracy: 0.9946\n",
            "Epoch 115/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4640 - accuracy: 0.9973\n",
            "Epoch 00115: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4641 - accuracy: 0.9973 - val_loss: 1.4661 - val_accuracy: 0.9952\n",
            "Epoch 116/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4642 - accuracy: 0.9969\n",
            "Epoch 00116: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4642 - accuracy: 0.9969 - val_loss: 1.4660 - val_accuracy: 0.9950\n",
            "Epoch 117/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4639 - accuracy: 0.9976\n",
            "Epoch 00117: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4639 - accuracy: 0.9976 - val_loss: 1.4658 - val_accuracy: 0.9956\n",
            "Epoch 118/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4641 - accuracy: 0.9971\n",
            "Epoch 00118: val_accuracy did not improve from 0.99560\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4641 - accuracy: 0.9971 - val_loss: 1.4658 - val_accuracy: 0.9951\n",
            "Epoch 119/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4642 - accuracy: 0.9970\n",
            "Epoch 00119: val_accuracy improved from 0.99560 to 0.99571, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 10s 40ms/step - loss: 1.4642 - accuracy: 0.9970 - val_loss: 1.4657 - val_accuracy: 0.9957\n",
            "Epoch 120/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4643 - accuracy: 0.9969\n",
            "Epoch 00120: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4643 - accuracy: 0.9969 - val_loss: 1.4662 - val_accuracy: 0.9948\n",
            "Epoch 121/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4641 - accuracy: 0.9972\n",
            "Epoch 00121: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4640 - accuracy: 0.9973 - val_loss: 1.4656 - val_accuracy: 0.9955\n",
            "Epoch 122/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4642 - accuracy: 0.9971\n",
            "Epoch 00122: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4642 - accuracy: 0.9971 - val_loss: 1.4658 - val_accuracy: 0.9954\n",
            "Epoch 123/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4642 - accuracy: 0.9971\n",
            "Epoch 00123: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4642 - accuracy: 0.9971 - val_loss: 1.4664 - val_accuracy: 0.9945\n",
            "Epoch 124/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4638 - accuracy: 0.9975\n",
            "Epoch 00124: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4638 - accuracy: 0.9975 - val_loss: 1.4658 - val_accuracy: 0.9952\n",
            "Epoch 125/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4641 - accuracy: 0.9973\n",
            "Epoch 00125: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4641 - accuracy: 0.9973 - val_loss: 1.4660 - val_accuracy: 0.9955\n",
            "Epoch 126/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4645 - accuracy: 0.9967\n",
            "Epoch 00126: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4646 - accuracy: 0.9967 - val_loss: 1.4662 - val_accuracy: 0.9948\n",
            "Epoch 127/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4644 - accuracy: 0.9968\n",
            "Epoch 00127: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4644 - accuracy: 0.9968 - val_loss: 1.4661 - val_accuracy: 0.9949\n",
            "Epoch 128/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4638 - accuracy: 0.9975\n",
            "Epoch 00128: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4638 - accuracy: 0.9976 - val_loss: 1.4659 - val_accuracy: 0.9955\n",
            "Epoch 129/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4640 - accuracy: 0.9974\n",
            "Epoch 00129: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4640 - accuracy: 0.9974 - val_loss: 1.4658 - val_accuracy: 0.9955\n",
            "Epoch 130/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4641 - accuracy: 0.9970\n",
            "Epoch 00130: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4641 - accuracy: 0.9970 - val_loss: 1.4659 - val_accuracy: 0.9954\n",
            "Epoch 131/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4643 - accuracy: 0.9969\n",
            "Epoch 00131: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4643 - accuracy: 0.9969 - val_loss: 1.4659 - val_accuracy: 0.9951\n",
            "Epoch 132/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4639 - accuracy: 0.9974\n",
            "Epoch 00132: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4639 - accuracy: 0.9974 - val_loss: 1.4655 - val_accuracy: 0.9956\n",
            "Epoch 133/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4640 - accuracy: 0.9974\n",
            "Epoch 00133: val_accuracy did not improve from 0.99571\n",
            "262/262 [==============================] - 10s 38ms/step - loss: 1.4639 - accuracy: 0.9974 - val_loss: 1.4656 - val_accuracy: 0.9954\n",
            "Epoch 134/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4641 - accuracy: 0.9971\n",
            "Epoch 00134: val_accuracy improved from 0.99571 to 0.99595, saving model to Digit Recognizer/model.hdf5\n",
            "262/262 [==============================] - 11s 40ms/step - loss: 1.4641 - accuracy: 0.9971 - val_loss: 1.4653 - val_accuracy: 0.9960\n",
            "Epoch 135/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4639 - accuracy: 0.9974\n",
            "Epoch 00135: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4639 - accuracy: 0.9974 - val_loss: 1.4658 - val_accuracy: 0.9956\n",
            "Epoch 136/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4639 - accuracy: 0.9973\n",
            "Epoch 00136: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4639 - accuracy: 0.9973 - val_loss: 1.4657 - val_accuracy: 0.9954\n",
            "Epoch 137/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4639 - accuracy: 0.9974\n",
            "Epoch 00137: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4639 - accuracy: 0.9974 - val_loss: 1.4656 - val_accuracy: 0.9955\n",
            "Epoch 138/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4641 - accuracy: 0.9972\n",
            "Epoch 00138: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4641 - accuracy: 0.9972 - val_loss: 1.4656 - val_accuracy: 0.9955\n",
            "Epoch 139/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4638 - accuracy: 0.9976\n",
            "Epoch 00139: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4638 - accuracy: 0.9976 - val_loss: 1.4656 - val_accuracy: 0.9952\n",
            "Epoch 140/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4638 - accuracy: 0.9973\n",
            "Epoch 00140: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4638 - accuracy: 0.9973 - val_loss: 1.4655 - val_accuracy: 0.9957\n",
            "Epoch 141/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4636 - accuracy: 0.9978\n",
            "Epoch 00141: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 11s 40ms/step - loss: 1.4636 - accuracy: 0.9978 - val_loss: 1.4659 - val_accuracy: 0.9952\n",
            "Epoch 142/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4639 - accuracy: 0.9974\n",
            "Epoch 00142: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4639 - accuracy: 0.9974 - val_loss: 1.4657 - val_accuracy: 0.9955\n",
            "Epoch 143/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4639 - accuracy: 0.9974\n",
            "Epoch 00143: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4639 - accuracy: 0.9974 - val_loss: 1.4662 - val_accuracy: 0.9951\n",
            "Epoch 144/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4640 - accuracy: 0.9972\n",
            "Epoch 00144: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4640 - accuracy: 0.9973 - val_loss: 1.4659 - val_accuracy: 0.9952\n",
            "Epoch 145/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4637 - accuracy: 0.9976\n",
            "Epoch 00145: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4637 - accuracy: 0.9976 - val_loss: 1.4657 - val_accuracy: 0.9955\n",
            "Epoch 146/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4641 - accuracy: 0.9974\n",
            "Epoch 00146: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4640 - accuracy: 0.9974 - val_loss: 1.4656 - val_accuracy: 0.9958\n",
            "Epoch 147/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4641 - accuracy: 0.9973\n",
            "Epoch 00147: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4641 - accuracy: 0.9973 - val_loss: 1.4657 - val_accuracy: 0.9955\n",
            "Epoch 148/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4642 - accuracy: 0.9970\n",
            "Epoch 00148: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4642 - accuracy: 0.9970 - val_loss: 1.4654 - val_accuracy: 0.9958\n",
            "Epoch 149/150\n",
            "262/262 [==============================] - ETA: 0s - loss: 1.4641 - accuracy: 0.9972\n",
            "Epoch 00149: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4641 - accuracy: 0.9972 - val_loss: 1.4658 - val_accuracy: 0.9954\n",
            "Epoch 150/150\n",
            "261/262 [============================>.] - ETA: 0s - loss: 1.4637 - accuracy: 0.9976\n",
            "Epoch 00150: val_accuracy did not improve from 0.99595\n",
            "262/262 [==============================] - 10s 39ms/step - loss: 1.4638 - accuracy: 0.9976 - val_loss: 1.4656 - val_accuracy: 0.9955\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efea5876860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwulbt3yqTuv"
      },
      "source": [
        "## Load best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0a4aDWD3j8o"
      },
      "source": [
        "model = keras.models.load_model(\"Digit Recognizer/model.hdf5\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztYerCsOqZ9_"
      },
      "source": [
        "## Predict test and visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "P3_zKrC6G1U2",
        "outputId": "e15edd54-927f-4ae5-d79c-848ae088665b"
      },
      "source": [
        "pred_test = np.argmax(model.predict(x_test), axis=1)\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    index = np.random.randint(0, len(x_test)+1)\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.imshow(x_test[index, :, :, 0], cmap='gray')\n",
        "    plt.xlabel(pred_test[index])\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLsUtrigrvpY"
      },
      "source": [
        "## Create submission csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "JjUObWwlp5YC",
        "outputId": "1e402ce9-daa4-43b9-da8d-0988928e238c"
      },
      "source": [
        "df_submission[\"Label\"] = pred_test\n",
        "df_submission.to_csv(\"Digit Recognizer/submission.csv\", index=False)\n",
        "df_submission"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27995</th>\n",
              "      <td>27996</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27996</th>\n",
              "      <td>27997</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27997</th>\n",
              "      <td>27998</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27998</th>\n",
              "      <td>27999</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27999</th>\n",
              "      <td>28000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       ImageId  Label\n",
              "0            1      2\n",
              "1            2      0\n",
              "2            3      9\n",
              "3            4      0\n",
              "4            5      3\n",
              "...        ...    ...\n",
              "27995    27996      9\n",
              "27996    27997      7\n",
              "27997    27998      3\n",
              "27998    27999      9\n",
              "27999    28000      2\n",
              "\n",
              "[28000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48-CS79YrreG"
      },
      "source": [
        "# Rank225/2582 (Top 9%) YaYYYYYYY"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv0mfPH3tR1t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}